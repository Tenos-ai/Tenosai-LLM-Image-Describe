# Tenosai‚ÄØLLM‚ÄØImage‚ÄØDescribe

A swiss‚Äëarmy ComfyUI node that lets **any** vision‚Äëcapable LLM (OpenAI‚ÄØGPT‚Äë4o, Gemini‚ÄØ1.5‚ÄØPro Vision, Groq‚Äëmix‚Ä¶ you name it) rip through a reference image and return a prompt you can feed straight back into your diffusion pipeline‚Äîno hand‚Äëcrafting required.&#x20;

---

## Why you‚Äôll want it

| ‚ö°   | **Auto‚Äëprompt in three flavors** ‚Äì ‚ÄúStyle‚Äù, ‚ÄúSubject‚Äù, or ‚ÄúDescribe‚Äù modes let you yank out pure style cues, pure content, or a balanced mix‚Äîall enforced by detailed system prompts baked into the node.                                                 |
| --- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| üîë  | **API‚Äëkey juggling** ‚Äì Reads keys from `api_keys.json`, but you can hot‚Äëswap a key per‚Äënode at runtime if you‚Äôve got a second account (or if someone else is paying).                                                                                     |
| üñºÔ∏è | **Hash‚Äëbased caching** ‚Äì It won‚Äôt re‚Äëhit the LLM unless the image or model settings change, saving your tokens (and sanity).                                                                                                                              |
| üß©  | **CLIP‚Äëagnostic conditioning** ‚Äì Detects whatever encoding method your CLIP loader exposes (`encode_from_tokens`, `encode_conditioning`, `encode`, `encode_text`, or even a bare callable) and formats the output so the rest of your graph stays happy.  |
| üöë  | **Fails graceful‚Äëish** ‚Äì No API key? Vision‚Äëless model? Timeout? You get meaningful error text (and a blank conditioning tensor so the graph doesn‚Äôt hard‚Äëcrash).                                                                                         |

---

## File roster

```
custom_nodes/tenos_nodes/
‚îú‚îÄ llm_describe_node.py          ‚Üê the node itself
‚îú‚îÄ llm_models.json               ‚Üê list of provider ‚Üí model names
‚îî‚îÄ api_keys.json                 ‚Üê stash your secrets here (optional)
```

Both JSON helpers are optional but highly recommended‚Äîskip them and you‚Äôll feed keys/models manually.&#x20;

---

## Quick install

```bash
# Inside your ComfyUI install:
mkdir -p custom_nodes/tenos_nodes
cp llm_describe_node.py llm_models.json api_keys.json custom_nodes/tenos_nodes/
# restart ComfyUI
```

> **Heads‚Äëup:** the file expects to sit next to its two JSON sidekicks. If you rename the folder, update the import path in the code (line right after the imports).&#x20;

---

## JSON cheat‚Äësheets

### `api_keys.json`

```jsonc
{
  "openai_api_key":  "sk‚Äë...",
  "google_api_key":  "AIza...",
  "groq_api_key":    "gsk_..."
}
```

Keys map 1‚Äëto‚Äë1 with provider names via an internal lookup table.&#x20;

### `llm_models.json`

```jsonc
{
  "providers": {
    "openai":  { "models": ["gpt-4o-mini", "gpt-4o-vision-preview"] },
    "gemini":  { "models": ["gemini-pro-vision", "gemini-1.5-pro"] },
    "groq":    { "models": ["llama-3-70b-vision"] }
  }
}
```

Anything not listed still works‚Äîtype the full model string into the node‚Äôs dropdown or override box. The JSON just keeps the UI tidy.&#x20;

---

## Node I/O spec

| **Field**                       | **Type / UI**                    | **Description**                                                         |
| ------------------------------- | -------------------------------- | ----------------------------------------------------------------------- |
| `clip`                          | **CLIP**                         | Your text encoder. The node figures out how to talk to it.              |
| `image`                         | **IMAGE**                        | 4‚ÄëD tensor `(B,H,W,C)` from any loader.                                 |
| `llm_provider`                  | dropdown                         | Values sourced from `llm_models.json`; `"None"` skips the call.         |
| `llm_model`                     | dropdown                         | `"provider: model"` strings; editable.                                  |
| `description_mode`              | `["Style","Subject","Describe"]` | System‚Äëprompt preset.                                                   |
| `auto_describe_on_image_change` | boolean                          | If **false**, you must nudge the node (toggle a field) to refresh.      |
| `override_api_key`              | string (optional)                | Beats whatever‚Äôs in `api_keys.json` for this one call.                  |
| **Returns**                     | `CONDITIONING`                   | List `[[embeddings, {"pooled_output": pooled}]]` ready for SDXL / Flux. |

---

## Example ComfyUI graph (pseudo)

```
Loader ‚Üí Tenos LLM Image Describe (Style, GPT‚Äë4o‚Äëmini) ‚Üí SDXL Style LO ‚Üí Merge ‚Üí ...
```

Or go all‚Äëin:

```
Loader ‚Üí Split ‚Üí Tenos LLM Image Describe (Subject) ‚îÄ‚îê
         |                                          ‚îú‚Üí Combine Conditioning ‚Üí Diffusion
         ‚îî‚Üí Tenos LLM Image Describe (Style) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Pro tips

* **Batching:** Node loops images internally, hitting the LLM once per frame. Keep batches small if you value tokens.
* **Model sanity:** Some providers don‚Äôt expose vision models yet. If you point ‚Äúgroq: llama‚Äë3‚Äë70b‚Äù at a JPEG, it‚Äôll just ignore the picture and hallucinate‚Äîwatch the console warnings.&#x20;
* **Clip weirdness:** If your custom CLIP lacks pooled output, Flux will still run‚Äîjust with less global juice.

---

## Troubleshooting crib notes

| Symptom                                                         | Likely Cause                                                   | Fix                                                       |
| --------------------------------------------------------------- | -------------------------------------------------------------- | --------------------------------------------------------- |
| `Error: No API key provided‚Ä¶` in prompt output                  | Empty `api_keys.json` or bad override field                    | Paste key, restart                                        |
| Node prints `Unknown LLM provider`                              | Typo in dropdown or JSON                                       | Match provider names exactly (`openai`, `gemini`, `groq`) |
| Blank conditioning but no error                                 | `auto_describe_on_image_change` is **off** and nothing toggled | Tweak any field or feed a new image                       |
| `CLIP object ‚Ä¶ does not have a recognized text encoding method` | You forgot a CLIP loader                                       | Add a CLIP‚ÄëLoader node upstream                           |

---

Made with love and a dash of ‚Äúwhy hasn‚Äôt ComfyUI done this yet?‚Äù ‚ú®
